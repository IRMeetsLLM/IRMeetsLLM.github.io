<section id="schedule" class={{include.class}}>
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2 class="section-heading">Schedule</h2>
        <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
      </div>
    </div>
    <div class="row text-justify">
      <div class="col-md-12">
        <p class="large text-muted">
          Welcome to our workshop! We are pleased to host four distinguished researchers who will deliver keynote presentations on cutting-edge technologies in large language models and information retrieval. Additionally, authors of eight accepted papers will provide oral presentations. We eagerly anticipate your participation as we explore the development and future prospects of information retrieval technology in the era of large language models. Join us for an engaging discussion on this dynamic field! The full schedule is available at the official websit of <a href="https://www2024.thewebconf.org/program/full-schedule/">WWW 2024</a>.
        </p>
        <div class="col-lg-12 text-center">
        <h3 class="section-subheading">Keynote</h3>
        </div>
        <ul class="large text-muted">
          <li style="margin-bottom: 50px;"><strong>Nearest Neighbor Search on High-Dimensional Vector Data</strong>
              <ul>
                  <li><strong>Time:</strong> May 13, 2024, 9:30 AM – 10:00 AM </li>
                  <li><strong>Speaker:</strong> Cheng Long, Associate Professor, Nanyang Technological University</li>
                  <li><strong>Abstract:</strong> Vector data is becoming ubiquitous in the era of deep learning and generative AI. A fundamental operator on vector data is the approximate K nearest neighbor (AKNN) search, which retrieves from a database of vectors those that are close to a query vector. AKNN has also been used as a popular information retrieval method. Many algorithms have been developed for AKNN. We observe that in high-dimensional space, the time consumption of nearly all AKNN algorithms is dominated by that of the distance comparison operations (DCOs). For each operation, it scans full dimensions of an object and thus, runs in linear time wrt the dimensionality. In this talk, I will introduce a new randomized algorithm named ADSampling which runs in logarithmic time wrt to the dimensionality for the majority of DCOs and succeeds with high probability. In addition, I will introduce one general and two algorithm-specific techniques based on ADSampling, which can be used as plugins to enhance existing AKNN algorithms. I will also briefly introduce a new quantization method for high-dimensional vectors, which can be used for enhancing the efficiency of AKNN, and finally discuss some future research directions of AKNN.</li>
                  <li><strong>Bio:</strong> Cheng Long is an Associate Professor at the School of Computer Science and Engineering (SCSE), Nanyang Technological University (NTU). He earned his Ph.D. degree from Hong Kong University of Science and Technology (HKUST) in 2015 and his Bachelor's degree from South China University of Technology (SCUT) in 2010. He has research interests broadly in data management and data mining. Specifically, he works in high-dimensional vector data management (and its applications in large models such as retrieval-augmented generative AI), spatial data management with machine learning-based techniques, spatial data mining in the urban domain (e.g., traffic and mobility analysis), and graph data mining (including dense subgraph mining and graphlet mining). His work has garnered recognition and accolades, including the prestigious "Best Research Award" from ACM-Hong Kong, the "Fulbright-RGC Research Award" granted by the Research Grant Council (Hong Kong), the "PG Paper Contest Award" bestowed by IEEE-HK, and the "Overseas Research Award" received from HKUST.</li>
              </ul>
          </li>
          <li style="margin-bottom: 50px;"><strong>Understanding and Patching LLMs from a Compositional Reasoning Perspective</strong>
              <ul>
                  <li><strong>Time:</strong> May 13, 2024, 10:00 AM – 10:30 AM </li>
                  <li><strong>Speaker:</strong> Ying Wei, Assistant Professor, Nanyang Technological University</li>
                  <li><strong>Abstract:</strong> LLMs have marked a revolutonary shift, yet they falter when faced with compositional reasoning tasks. This talk introduces our empirical findings that (1) most of compositional reasoning failures of LLMs stem from the improperly generated or leveraged implicit reasoning results, (2) implicit reasoning results indeed surface within middle layers and play a causative role in shaping the final explicit reasoning results, and (3) multi-head self-attention (MHSA) modules within these layers emerge as the linchpins in accurate generation and leveraging of implicit reasoning results. The second part of this talk comes our proposed method CREME, which is a lightweight method grounded on the above findings to patch errors in compositional reasoning via editing the located MHSA modules. CREME paves the way for autonomously and continuously enhancing compositional reasoning capabilities in language models.</li>
                  <li><strong>Bio:</strong> Ying Wei is a Nanyang Assistant Professor in the School of Computer Science and Engineering at Nanyang Technological University. Prior to that, she was an Assistant Professor in the Department of Computer Science, City University of Hong Kong and a Senior Researcher at the Machine Learning Center of Tencent AI Lab. She works on machine learning, and is especially interested in solving challenges in transfer, meta, and continual learning through compositionality. She received her Ph.D. degree from Hong Kong University of Science and Technology in 2017 with the support of Hong Kong PhD Fellowship. She has published over 55 papers in conferences such as ICML and NeurIPS, and received the SIGKDD’14 Best Paper nomination.She has served as action editor for TMLR, area chairs for ICML and NeurIPS, a senior program committee member for AAAI, and a committee member for conferences such as ICLR and ACL.</li>
              </ul>
          </li>
          <li style="margin-bottom: 50px;"><strong>Coffee Break</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 10:30 AM – 11:00 AM </li>
            </ul>
          </li>
          <li style="margin-bottom: 50px;"><strong>Efficient Multimodal Large Language Model</strong>
              <ul>
                  <li><strong>Time:</strong> May 13, 2024, 11:00 AM – 11:30 AM </li>
                  <li><strong>Speaker:</strong> Ao Zhang, Ph.D. Student, National University of Singapore</li>
                  <li><strong>Abstract:</strong> Recent years have witnessed a great rise in multimodal large language models (MLLMs) in ushering the human-like artificial intelligence. However, the construction of MLLMs typically requires heavy computational costs. In this talk, we will introduce efficient MLLM construction from several aspects. What is an efficient MLLM architecture to achieve high performance? How to choose and organize the data to build a powerful MLLM? Are there training strategies to build new MLLMs or extend function scope efficiently?</li>
                  <li><strong>Bio:</strong> Ao Zhang is currently a Ph.D. student in the School of Computing, the National University of Singapore. His research interests mainly lie in multimodal large language models, multimodal prompt learning, and structured scene understanding. He has published several papers on top-tier conferences including ICCV, ECCV, ACL, EMNLP, AAAI, and NeurIPS.</li>
              </ul>
          </li>
          <li><strong>Towards Generative Search and Recommendation in the Era of Large Language Models</strong>
              <ul>
                  <li><strong>Time:</strong> May 13, 2024, 11:30 AM – 12:00 AM </li>
                  <li><strong>Speaker:</strong> Wenjie Wang, Research Fellow, National University of Singapore</li>
                  <li><strong>Abstract:</strong> With the information explosion on the Web, search and recommendation are foundational infrastructures to satisfying users' information needs. As the two sides of the same coin, both revolve around the same core research problem, matching queries with documents or users with items. In recent decades, search and recommendation have experienced synchronous technological paradigm shifts, including machine learning-based and deep learning-based paradigms. Recently, the superintelligent generative large language models have sparked a new paradigm in search and recommendation --- generative search (retrieval) and recommendation, which aims to address the matching problem in a generative manner. In this talk, we provide a comprehensive survey of this emerging generative paradigm and summarize the developments in generative search and recommendation from a unified perspective. Besides, we distinguish generative search and recommendation with their unique challenges, identify open problems and future directions, and envision the next information-seeking paradigm.</li>
                  <li><strong>Bio:</strong> Wenjie Wang is a research fellow at National University of Singapore, working with Prof. Chua Tat-Seng and Prof. Ng See-Kiong. He received the PhD degree from School of Computing, National University of Singapore in 2023, supervised by Prof. Chua Tat-Seng. His research interests cover LLM-based search and recommendation, causal inference, and multimedia. He has over 40 publications appeared in several top conferences and journals such as SIGIR, KDD, WWW, TIP, and TOIS. Moreover, he has been served as the guest editor, PC member and reviewer for the top conferences and journals including TOIS, TOIS, TKDE, SIGIR, KDD, WWW, and WSDM.</li>
              </ul>
          </li>
        </ul>
        <div class="col-lg-12 text-center">
        <h3 class="section-subheading">Oral Presentation</h3>
        </div>
        <ul class="large text-muted">
          <li><strong>ConvSDG: Session Data Generation for Conversational Search</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 2:00 PM – 2:15 PM </li>
              <li><strong>Speaker:</strong> Fengran Mo, Department of Computer Science and Operations Research, Université de Montréal</li>
            </ul>
          </li>  
          <li><strong>Heterogeneous Knowledge Grounding for Medical Question Answering with Retrieval Augmented Large Language Model</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 2:15 PM – 2:30 PM </li>
              <li><strong>Speaker:</strong> Wenting Zhao, University of Illinois Chicago</li>
            </ul>
          </li>  
          <li><strong>Weakly Supervised Video Moment Retrieval via Location-irrelevant Proposal Learning</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 2:30 PM – 2:45 PM </li>
              <li><strong>Speaker:</strong> Wei Ji, National University of Singapore</li>
            </ul>
          </li>  
          <li><strong>One-step Reach: LLM-based Keyword Generation for Sponsored Search Advertising</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 2:45 PM – 3:00 PM </li>
              <li><strong>Speaker:</strong> Zheyi Sha, Baidu Inc.</li>
            </ul>
          </li>  
          <li><strong>Coffee Break</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 3:00 PM – 3:30 PM </li>
            </ul>
          </li>
          <li><strong>Neural Retrievers are Biased Towards LLM-Generated Content</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 3:30 PM – 3:45 PM </li>
              <li><strong>Speaker:</strong> Liang Pang, Institute of Computing Technology, Chinese Academy of Sciences (ICT)</li>
            </ul>
          </li>  
          <li><strong>A Case Study of Enhancing Sparse Retrieval using LLMs</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 3:45 PM – 4:00 PM </li>
              <li><strong>Speaker:</strong> Michael Ayoub, University of Copenhagen</li>
            </ul>
          </li>  
          <li><strong>LLM Driven Web Profile Extraction for Identical Names</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 4:00 PM – 4:15 PM </li>
              <li><strong>Speaker:</strong> Prateek Sancheti, IIIT Hyderabad</li>
            </ul>
          </li>  
          <li><strong>Bi-CAT: Improving Robustness of LLM-based Text Rankers to Conditional Distribution Shifts</strong>
            <ul>
              <li><strong>Time:</strong> May 13, 2024, 4:15 PM – 4:30 PM </li>
              <li><strong>Speaker:</strong> Sriram Srinivasan & Rishabh Deshmukh, Amazon</li>
            </ul>
          </li>  
        </ul>
      </div>
    </div>
  </div>
</section>
