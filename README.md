# Information Retrieval Meets Large Language Models Workshop

## Summary

The advent of large language models (LLMs) presents both opportunities and challenges for the information retrieval (IR) community. On one hand, LLMs will revolutionize how people access information, meanwhile the retrieval techniques can play a crucial role in addressing many inherent limitations of LLMs. On the other hand, there are open problems regarding the collaboration of retrieval and generation, the potential risks of misinformation, and the concerns about cost-effectiveness. To seize the critical moment for development, it calls for the joint effort from academia and industry on many key issues, including identification of new research problems, proposal of new techniques, and creation of new evaluation protocols. It has been one year since the launch of ChatGPT in November last year, and the entire community is currently undergoing a profound transformation in techniques. Therefore, this workshop will be a timely venue to exchange ideas and forge collaborations.


## Call for Papers

At the heart of the "Information Retrieval Meets Large Language Models Workshop" lies the ambition to pioneer research that bridges the gap between information retrieval and large language models (LLMs). This workshop is dedicated to exploring how LLMs can enhance information retrieval algorithms, introducing a new era of data processing and analysis. We aim to delve into the potential of generative models, particularly in creating AI-generated content (AIGC), to supplement and diversify the information available, catering to a broader array of user preferences and information needs.

A significant focus will be on the transformative potential of LLMs in reshaping user interactions with information retrieval systems, harnessing the latest advancements in conversational AI and user experience design. In parallel, the workshop will address the critical issues of trust and ethics in AI-driven information retrieval. This involves scrutinizing content authenticity, mitigating algorithmic biases, and ensuring adherence to evolving ethical and legal standards.

Furthermore, the workshop endeavors to promote the development and adoption of innovative evaluation methodologies. These new approaches, including advanced metrics and human-centered evaluation techniques, are essential for assessing the effectiveness and impact of LLM-enhanced information retrieval systems. Through these multifaceted objectives, the workshop aspires to set a new benchmark in the integration of information retrieval and large language models, paving the way for future innovations in the field.

**Topics of Interest:** We invite original submissions that address, but are not limited to, the following areas:

1. **LLMs in Query Understanding and Reformulation:**
   - Exploring the use of LLMs for interpreting and rephrasing ambiguous queries, including query expansion with semantic understanding and contextual query reformulation.

2. **LLMs in Understanding User Behavior:**
   - Utilizing LLMs to predict user satisfaction in search sessions and personalize search results based on analysis of historical user data.

3. **Personalized Search Techniques Using LLMs:**
   - Developing user profiles with the aid of LLMs to improve search relevance and constructing personalized knowledge graphs.

4. **Conversational Search Powered by LLMs:**
   - Innovations in dialogue systems for search and continuous learning from user interactions in conversational information retrieval.

5. **LLM-driven Indexing Strategies:**
   - Implementing LLM-based models for generative retrieval, index pruning, optimization, and creating abstract document representations.

6. **Ranking and Matching with LLMs:**
   - Using LLMs for contextual ranking, semantic query-document matching, and multi-modal search result ranking.

7. **LLMs in Evaluation Metrics for Information Retrieval:**
   - Developing new IR evaluation metrics leveraging LLM language understanding, automating relevance judgment, and emulating user satisfaction testing.

8. **Data Augmentation for IR with LLMs:**
   - Generating synthetic queries and enhancing IR corpora diversity using LLM-generated content.

9. **Incorporating IR Techniques in LLM Pre-training:**
   - Merging traditional IR methods with LLM pre-training for domain adaptation, retrieval-enhanced strategies, and impact analysis.

10. **Retrieval Adapters for Enhancing LLMs:**
    - Creating modular retrieval adapters for specific IR tasks and customizable IR features within LLMs, improving transfer learning.

11. **Knowledge-Enriched LLMs for IR:**
    - Integrating external knowledge bases with LLMs, using IR for real-time data feeding, and enhancing factual accuracy with dynamic retrieval.

12. **Retrieval Augmented Generation for LLMs:**
    - Leveraging document retrieval to enrich LLM responses, comparing RAG with end-to-end models, and examining complex reasoning strategies.

13. **Hybrid Models of LLMs and Classic IR:**
    - Evaluating hybrid models in specialized domains, enhancing classic IR models' features with LLMs, and maintaining system interpretability.

14. **Training and Reasoning Strategies for LLMs in IR:**
    - Implementing feedback loops, multi-task learning, meta-learning, few-shot learning, explainable AI, transfer learning, and scalability in LLM training for IR.

15. **Extensions in Multi-Lingual and Multi-Modal Scenarios:**
    - Investigating LLMs in cross-lingual retrieval, enhancing multi-lingual corpora, interpreting and indexing multi-modal data, and integrating LLMs with other modalities for unified search platforms.

Submissions must be in a single PDF file, formatted according to the ACM WWW 2024 template. Papers may range from 4 to 8 pages, with additional unlimited pages for references. Authors can choose the length of their paper, as no distinction will be made between long and short papers. All submissions will undergo a "double-blind" review process, evaluated for their relevance, scientific novelty, and technical quality by expert reviewers.

## Important Dates

Paper Submissions Deadline: February 5, 2024 (11:59 PM, AoE)

Acceptance Notification: March 4, 2024 (11:59 PM, AoE)

Workshop Date: May 14, 2024

## Workshop Organizers:

Wenjie Wang, National University of Singapore
Yang Zhang, University of Science and Technology of China
Xinyu Lin, National University of Singapore
Fuli Feng, University of Science and Technology of China
Weiwen Liu, Huawei Noah's Ark Lab, China
Yong Liu, Huawei Noah's Ark Lab, Singapore
Wayne Xin Zhao, Renmin University of China
Xiangnan He, University of Science and Technology of China


## Contact

wenjiewang96@gmail.com



