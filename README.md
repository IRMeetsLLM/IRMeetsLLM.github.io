# GENERATIVE-REC.github.io

## Workshop Title: The 2nd Workshop on Recommendation with Generative Models


## Summary

The rise of generative models has driven significant advancements in recommender systems, leaving unique opportunities for enhancing usersâ€™ personalized recommendations. This workshop serves as a platform for researchers to explore and exchange innovative concepts related to the integration of generative models into recommender systems. It primarily focuses on five key perspectives: (i) improving recommender algorithms, (ii) generating personalized content, (iii) evolving the user-system interaction paradigm, (iv) enhancing trustworthiness checks, and (v) refining evaluation methodologies for generative recommendations. With generative models advancing rapidly, an increasing body of research is emerging in these domains, underscoring the timeliness and critical importance of this workshop. The related research will introduce
innovative technologies to recommender systems and contribute to fresh challenges in both academia and industry. In the long term, this research direction has the potential to revolutionize the traditional recommender paradigms and foster the development of next-generation recommender systems.


## Call for Papers

The main objective of this workshop is to encourage pioneering research in the integration of generative models with recommender systems, with a specific focus on five key aspects. First, this workshop will motivate active researchers to utilize generative models for enhancing recommender algorithms and refining user modeling. Second, it promotes utilizing generative models to generate diverse content, i.e., AI-generated content (AIGC), in certain situations, complementing human-generated content to satisfy a broader range of user preferences and information needs. Third, it embraces substantial innovations in user interactions with recommender systems, possibly driven by the boom of large language models (LLMs). Fourth, the workshop will highlight the significance of trust in employing generative models for recommendations, encompassing aspects like content trustworthiness, algorithmic biases, and adherence to evolving ethical and legal standards. Lastly, the workshop will prompt researchers to develop diverse methods for the evaluation, including novel metrics and human evaluation approaches.

The workshop provides an invaluable forum for researchers to present the latest advancements in the rapidly evolving field of recommender systems. We welcome original submissions focusing on generative models in recommender systems, including a range of relevant topics:

1) Leveraging LLMs and other generative models such as diffusion models to improve user modeling and various recommendation tasks, including sequential, cold-start, social, conversational, multimodal, and causal recommendation tasks.
2) Improving generative recommender models (e.g., LLM-based recommenders) from different aspects, such as model architecture, and training and inference efficiency.
3) Combining external knowledge from LLMs or other generative models to enhance user and item representation learning.
4) Generative recommendation by harnessing generative AI to drive personalized item creation or editing, particularly in contexts such as advertisement, image, and micro-video.
5) Innovation of user-system interaction paradigm for effective user feedback by leveraging strong conversational capability of LLMs.
6) Real-world applications of generative recommender systems, ranging from finance to streaming platforms and social networks.
7) Trustworthy recommendation with generative models, for example, developing the standards and technologies to improve or inspect the recommendations from the aspects of bias, fairness, privacy, safety, authenticity, legal compliance, and identifiability.
8) Developing generative agents empowered by LLMs, motivating the recommendation agents from user simulation and data collection, to algorithm enhancement and evaluation.
9) Evaluation of generative recommender systems, including new evaluation metrics, standards, and human evaluation approaches.

Submitted papers must be a single PDF file in the template of ACM WWW 2024. Submissions can be of varying length from 4 to 8 pages, plus unlimited pages for references. The authors may decide on the appropriate length of the paper as no distinction is made between long and short papers. All submitted papers will follow the "double-blind" review policy and undergo the same review process and duration. Expert peer reviewers in the field will assess all papers based on their relevance to the workshop, scientific novelty, and technical quality.

We are also preparing an ACM TOIS special issue on using generative models for recommendation. High-quality submissions will be recommended to submit to this special issue.


## Important Dates

Paper Submissions Deadline: February 5, 2024 (11:59 PM, AoE)
Acceptance Notification: March 4, 2024 (11:59 PM, AoE)
Workshop Date: May 14, 2024

## Workshop Organizers:

Wenjie Wang, National University of Singapore
Yang Zhang, University of Science and Technology of China
Xinyu Lin, National University of Singapore
Fuli Feng, University of Science and Technology of China
Weiwen Liu, Huawei Noah's Ark Lab, China
Yong Liu, Huawei Noah's Ark Lab, Singapore
Wayne Xin Zhao, Renmin University of China
Xiangnan He, University of Science and Technology of China


## Contact

wenjiewang96@gmail.com



